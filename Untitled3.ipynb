{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a38762-72a6-42f6-9cf3-e5a2cdfc6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŒ² Tree 1\n",
      "X_2 <= 1.9 ? 0.35596471471471464\n",
      " left:Iris-setosa\n",
      " right:X_3 <= 1.5 ? 0.46777279209711636\n",
      "  left:Iris-versicolor\n",
      "  right:X_2 <= 4.8 ? 0.014739229024943401\n",
      "    left:X_0 <= 5.9 ? 0.4444444444444444\n",
      "        left:Iris-versicolor\n",
      "        right:Iris-virginica\n",
      "    right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 2\n",
      "X_2 <= 1.9 ? 0.3211495983935743\n",
      " left:Iris-setosa\n",
      " right:X_2 <= 4.9 ? 0.4479363236076839\n",
      "  left:X_1 <= 2.9 ? 0.010416666666666574\n",
      "    left:Iris-versicolor\n",
      "    right:X_3 <= 1.5 ? 0.11111111111111102\n",
      "        left:Iris-versicolor\n",
      "        right:Iris-virginica\n",
      "  right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 3\n",
      "X_2 <= 1.9 ? 0.3294804526748971\n",
      " left:Iris-setosa\n",
      " right:X_3 <= 1.5 ? 0.49809480262155165\n",
      "  left:Iris-versicolor\n",
      "  right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 4\n",
      "X_3 <= 0.4 ? 0.3672041062801933\n",
      " left:Iris-setosa\n",
      " right:X_2 <= 5.0 ? 0.34772839397625077\n",
      "  left:X_3 <= 1.7 ? 0.15187696745295448\n",
      "    left:X_1 <= 2.5 ? 0.013388321080628832\n",
      "        left:X_3 <= 1.3 ? 0.2975206611570247\n",
      "                left:Iris-versicolor\n",
      "                right:Iris-virginica\n",
      "        right:Iris-versicolor\n",
      "    right:Iris-virginica\n",
      "  right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 5\n",
      "X_3 <= 1.5 ? 0.3163333333333332\n",
      " left:X_3 <= 0.4 ? 0.4715789473684211\n",
      "  left:Iris-setosa\n",
      "  right:X_2 <= 4.9 ? 0.09972299168975082\n",
      "    left:Iris-versicolor\n",
      "    right:Iris-virginica\n",
      " right:X_2 <= 5.0 ? 0.012800000000000006\n",
      "  left:X_3 <= 1.8 ? 0.11999999999999983\n",
      "    left:X_2 <= 4.5 ? 0.5\n",
      "        left:Iris-virginica\n",
      "        right:Iris-versicolor\n",
      "    right:Iris-virginica\n",
      "  right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 6\n",
      "X_0 <= 5.9 ? 0.19180555555555545\n",
      " left:X_3 <= 0.4 ? 0.43477777777777776\n",
      "  left:Iris-setosa\n",
      "  right:X_2 <= 4.8 ? 0.1346782608695653\n",
      "    left:X_3 <= 1.5 ? 0.039697542533081207\n",
      "        left:Iris-versicolor\n",
      "        right:X_0 <= 4.9 ? 0.5\n",
      "                left:Iris-virginica\n",
      "                right:Iris-versicolor\n",
      "    right:Iris-virginica\n",
      " right:X_2 <= 5.0 ? 0.2895652173913045\n",
      "  left:X_3 <= 1.7 ? 0.3402646502835538\n",
      "    left:Iris-versicolor\n",
      "    right:Iris-virginica\n",
      "  right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 7\n",
      "X_2 <= 5.0 ? 0.2968428184281845\n",
      " left:X_3 <= 0.4 ? 0.4408804283164781\n",
      "  left:Iris-setosa\n",
      "  right:X_3 <= 1.5 ? 0.09386666666666664\n",
      "    left:Iris-versicolor\n",
      "    right:X_1 <= 2.5 ? 0.22222222222222218\n",
      "        left:Iris-virginica\n",
      "        right:X_1 <= 3.0 ? 0.11111111111111116\n",
      "                left:X_2 <= 4.8 ? 0.5\n",
      "                                left:Iris-virginica\n",
      "                                right:Iris-versicolor\n",
      "                right:Iris-versicolor\n",
      " right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 8\n",
      "X_0 <= 5.4 ? 0.21878703703703706\n",
      " left:X_2 <= 1.9 ? 0.19901234567901233\n",
      "  left:Iris-setosa\n",
      "  right:X_0 <= 4.9 ? 0.2777777777777777\n",
      "    left:Iris-virginica\n",
      "    right:Iris-versicolor\n",
      " right:X_3 <= 1.7 ? 0.40900056980056987\n",
      "  left:X_1 <= 3.2 ? 0.2603550295857988\n",
      "    left:Iris-versicolor\n",
      "    right:Iris-setosa\n",
      "  right:X_2 <= 4.8 ? 0.054012345679012475\n",
      "    left:Iris-versicolor\n",
      "    right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 9\n",
      "X_2 <= 1.9 ? 0.349258658008658\n",
      " left:Iris-setosa\n",
      " right:X_2 <= 4.7 ? 0.4061797463842229\n",
      "  left:X_3 <= 1.5 ? 0.06444444444444448\n",
      "    left:Iris-versicolor\n",
      "    right:Iris-virginica\n",
      "  right:X_1 <= 3.0 ? 0.006390967432694891\n",
      "    left:Iris-virginica\n",
      "    right:X_3 <= 1.8 ? 0.1291810841983853\n",
      "        left:X_2 <= 4.9 ? 0.4444444444444445\n",
      "                left:Iris-versicolor\n",
      "                right:Iris-virginica\n",
      "        right:Iris-virginica\n",
      "\n",
      "ðŸŒ² Tree 10\n",
      "X_3 <= 0.4 ? 0.33755801687763703\n",
      " left:Iris-setosa\n",
      " right:X_2 <= 5.0 ? 0.4076575029947887\n",
      "  left:X_2 <= 4.7 ? 0.05804988662131516\n",
      "    left:Iris-versicolor\n",
      "    right:X_3 <= 1.7 ? 0.32000000000000006\n",
      "        left:Iris-versicolor\n",
      "        right:X_3 <= 1.8 ? 0.019999999999999796\n",
      "                left:Iris-virginica\n",
      "                right:Iris-virginica\n",
      "  right:Iris-virginica\n",
      "Random Forest Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Node class \n",
    "\n",
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        # for decision node\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        # for leaf node\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "# Decision Tree Classifier\n",
    "\n",
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2, n_features=None):\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features  # random subset of features\n",
    "\n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        X, Y = dataset[:, :-1], dataset[:, -1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "\n",
    "        # choose random subset of features if n_features set\n",
    "        feature_indices = np.arange(num_features)\n",
    "        if self.n_features:\n",
    "            feature_indices = np.random.choice(num_features, self.n_features, replace=False)\n",
    "\n",
    "        # split until stopping conditions are met\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, feature_indices)\n",
    "            if best_split and best_split[\"info_gain\"] > 0:\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth + 1)\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth + 1)\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "\n",
    "        # leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def get_best_split(self, dataset, feature_indices):\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "\n",
    "        for feature_index in feature_indices:\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            for threshold in possible_thresholds:\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    if curr_info_gain > max_info_gain:\n",
    "                        best_split = {\n",
    "                            \"feature_index\": feature_index,\n",
    "                            \"threshold\": threshold,\n",
    "                            \"dataset_left\": dataset_left,\n",
    "                            \"dataset_right\": dataset_right,\n",
    "                            \"info_gain\": curr_info_gain\n",
    "                        }\n",
    "                        max_info_gain = curr_info_gain\n",
    "\n",
    "        return best_split if max_info_gain != -float(\"inf\") else None\n",
    "\n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode == \"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l * self.gini_index(l_child) + weight_r * self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
    "        return gain\n",
    "\n",
    "    def entropy(self, y):\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "\n",
    "    def gini_index(self, y):\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 1\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini -= p_cls ** 2\n",
    "        return gini\n",
    "\n",
    "    def calculate_leaf_value(self, Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "        \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)    \n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.make_prediction(x, self.root) for x in X]\n",
    "\n",
    "    def make_prediction(self, x, tree):\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "class RandomForestClassifier():\n",
    "    def __init__(self, n_trees=10, min_samples_split=2, max_depth=2, n_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.trees = []\n",
    "\n",
    "    def bootstrap_sample(self, X, Y):\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[indices], Y[indices]\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTreeClassifier(\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_depth=self.max_depth,\n",
    "                n_features=self.n_features\n",
    "            )\n",
    "            X_sample, Y_sample = self.bootstrap_sample(X, Y)\n",
    "            tree.fit(X_sample, Y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        # majority vote\n",
    "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
    "        y_pred = [max(list(preds), key=list(preds).count) for preds in tree_preds]\n",
    "        return y_pred\n",
    "    \n",
    "    def print_forest(self):\n",
    "        for idx, tree in enumerate(self.trees):\n",
    "            print(f\"\\nðŸŒ² Tree {idx+1}\")\n",
    "            tree.print_tree()\n",
    "\n",
    "# Load dataset \n",
    "\n",
    "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
    "data = pd.read_csv(\"Iris.csv\", skiprows=1, header=None, names=col_names)\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1, 1)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
    "\n",
    "# -----------------------------\n",
    "# Train Random Forest\n",
    "# -----------------------------\n",
    "rf = RandomForestClassifier(n_trees=10, max_depth=5, n_features=2)\n",
    "rf.fit(X_train, Y_train)\n",
    "# Print all trees in the forest\n",
    "rf.print_forest()\n",
    "\n",
    "Y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb196794-0875-42d5-8b8d-8bb3972981d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
